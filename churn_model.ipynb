# churn_model.ipynb

# 1. Imports
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 2. Load Data
df = pd.read_csv("churn_prediction_dataset.csv")
print(df.head())

# 3. Data Preprocessing
df["Plan_Basic"] = (df["Subscription_Plan"] == "Basic").astype(int)
df["Plan_Standard"] = (df["Subscription_Plan"] == "Standard").astype(int)

features = [
    "Monthly_Purchases",
    "Total_Spend",
    "Support_Tickets",
    "Engagement_Score",
    "Plan_Basic",
    "Plan_Standard"
]

X = df[features]
y = df["Churn"]

# 4. Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 5. Model Training
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

# 6. Predictions & Evaluation
y_pred = model.predict(X_test)

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# 7. Feature Importance
importance = pd.Series(model.coef_[0], index=features)
importance.sort_values().plot(kind='barh', title='Feature Importance')
plt.xlabel("Coefficient Value")
plt.tight_layout()
plt.show()

# 8. Save Churn Probabilities
df["Churn_Probability"] = model.predict_proba(X)[:, 1]
df["Churn_Risk_Level"] = pd.cut(df["Churn_Probability"],
                                bins=[0, 0.33, 0.66, 1],
                                labels=["Low", "Medium", "High"])

df.to_csv("churn_with_predictions.csv", index=False)
print("\nPredictions saved to churn_with_predictions.csv")
